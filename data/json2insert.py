import json
from collections import defaultdict
import math

INPUT_FILE = "aladin_data.json"
OUTPUT_PREFIX = "insert_data_part"   # ì˜ˆ: insert_data_part1.sql, part2.sql ...

# ë§¤í•‘ ì €ì¥ì†Œ
publisher_map = {}
author_map = {}
translator_map = {}
category_map = {}
subcategory_map = {}
book_map = {}

# Auto-increment ì‹œë®¬ë ˆì´ì…˜
publisher_id = 1
author_id = 1
translator_id = 1
category_id = 1
subcategory_id = 1
book_id = 1

def escape(s):
    if s is None:
        return "NULL"
    return "'" + str(s).replace("'", "''") + "'"

with open(INPUT_FILE, "r", encoding="utf-8") as f:
    data = json.load(f)

sql = []
sql.append("-- Auto-generated SQL with filtering\n\n")

for item in data:

    title = item.get("title")
    price = item.get("priceSales") or "NULL"
    point = item.get("mileage") or "NULL"
    pub_date = item.get("pubDate")
    image_url = item.get("cover")
    description = item.get("description") or ""
    publisher = item.get("publisher")
    category_name = item.get("categoryName")

    # -----------------------------------------------------------
    # 1) ì¶œíŒì‚¬ ì¤‘ë³µ ì œê±°
    # -----------------------------------------------------------
    if publisher not in publisher_map:
        publisher_map[publisher] = publisher_id
        sql.append(
            f"INSERT INTO publisher (publisher_id, name) "
            f"VALUES ({publisher_id}, {escape(publisher)});"
        )
        publisher_id += 1

    publisher_fk = publisher_map[publisher]

    # -----------------------------------------------------------
    # 2) ì¹´í…Œê³ ë¦¬ / ì„œë¸Œì¹´í…Œê³ ë¦¬ ì¤‘ë³µ ì œê±° (2-depth)
    # -----------------------------------------------------------
    cat_parts = category_name.split(">")
    main_cat = cat_parts[0].strip()
    sub_cat = cat_parts[1].strip() if len(cat_parts) > 1 else main_cat

    if main_cat not in category_map:
        category_map[main_cat] = category_id
        sql.append(
            f"INSERT INTO category (category_id, category_name) "
            f"VALUES ({category_id}, {escape(main_cat)});"
        )
        category_id += 1

    if sub_cat not in subcategory_map:
        parent_fk = category_map[main_cat]
        subcategory_map[sub_cat] = subcategory_id
        sql.append(
            f"INSERT INTO subcategory (subcategory_id, category_id, subcategory_name) "
            f"VALUES ({subcategory_id}, {parent_fk}, {escape(sub_cat)});"
        )
        subcategory_id += 1

    sub_fk = subcategory_map[sub_cat]

    # -----------------------------------------------------------
    # 3) ì±…(book) ì¤‘ë³µ ì œê±°
    # -----------------------------------------------------------
    book_key = (title, publisher, pub_date)

    if book_key in book_map:
        current_book_id = book_map[book_key]
        continue

    book_map[book_key] = book_id
    current_book_id = book_id

    sql.append(
        f"INSERT INTO book (book_id, title, subcategory_id, publisher_id, price, point, "
        f"published_date, description, image_url) VALUES ("
        f"{book_id}, {escape(title)}, {sub_fk}, {publisher_fk}, {price}, {point}, "
        f"{escape(pub_date)}, {escape(description)}, {escape(image_url)});"
    )
    book_id += 1

    # -----------------------------------------------------------
    # 4) ì €ì / ë²ˆì—­ê°€ ì¤‘ë³µ ì œê±°
    # -----------------------------------------------------------
    raw_authors = item.get("author", "")
    authors_split = [x.strip() for x in raw_authors.split(",")]

    book_authors = []
    book_trans = []

    for name in authors_split:
        if not name:
            continue

        # ë²ˆì—­ê°€
        if "ì˜®ê¸´ì´" in name:
            clean = name.replace("(ì˜®ê¸´ì´)", "").replace("ì˜®ê¸´ì´", "").strip()

            if clean not in translator_map:
                translator_map[clean] = translator_id
                sql.append(
                    f"INSERT INTO translator (translator_id, name) "
                    f"VALUES ({translator_id}, {escape(clean)});"
                )
                translator_id += 1

            book_trans.append(translator_map[clean])

        else:
            clean = name.replace("(ì§€ì€ì´)", "").strip()

            if clean not in author_map:
                author_map[clean] = author_id
                sql.append(
                    f"INSERT INTO author (author_id, name) "
                    f"VALUES ({author_id}, {escape(clean)});"
                )
                author_id += 1

            book_authors.append(author_map[clean])

    # -----------------------------------------------------------
    # 5) ë§¤í•‘ í…Œì´ë¸”
    # -----------------------------------------------------------
    for aid in book_authors:
        sql.append(
            f"INSERT INTO book_author (book_id, author_id) "
            f"VALUES ({current_book_id}, {aid});"
        )

    for tid in book_trans:
        sql.append(
            f"INSERT INTO book_translator (book_id, translator_id) "
            f"VALUES ({current_book_id}, {tid});"
        )

# -----------------------------------------------------------
# 6) SQL íŒŒì¼ì„ 1000ì¤„ ë‹¨ìœ„ë¡œ ë¶„í•  ì €ì¥
# -----------------------------------------------------------
chunk_size = 1000
total = len(sql)
file_count = math.ceil(total / chunk_size)

for i in range(file_count):
    start = i * chunk_size
    end = start + chunk_size
    part_sql = sql[start:end]

    filename = f"{OUTPUT_PREFIX}{i+1}.sql"
    with open(filename, "w", encoding="utf-8") as f:
        f.write("\n".join(part_sql))

print("====================================")
print("ğŸ“Š ë°ì´í„° í†µê³„ ê²°ê³¼")
print("====================================")
print(f"ğŸ“š ì´ ë„ì„œ ìˆ˜: {len(book_map)}")
print(f"ğŸ¢ ì¶œíŒì‚¬ ìˆ˜: {len(publisher_map)}")
print(f"âœ ì €ì ìˆ˜: {len(author_map)}")
print(f"ğŸ”¤ ë²ˆì—­ê°€ ìˆ˜: {len(translator_map)}")
print(f"ğŸ“‚ ìƒì„±ëœ SQL íŒŒì¼ ìˆ˜: {file_count}")
print("====================================")
print(f"âœ” íŒŒì¼ prefix: {OUTPUT_PREFIX}*.sql")
